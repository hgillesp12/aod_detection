{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.14-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: opencv-python in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from albumentations) (1.14.1)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Downloading scikit_image-0.24.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from albumentations) (4.12.2)\n",
      "Collecting pydantic>=2.7.0 (from albumentations)\n",
      "  Downloading pydantic-2.9.0-py3-none-any.whl.metadata (146 kB)\n",
      "Collecting albucore>=0.0.13 (from albumentations)\n",
      "  Downloading albucore-0.0.14-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.2 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading pydantic_core-2.23.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tzdata in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2024.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in /Users/hannahgillespie/miniconda3/envs/ros2_env/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading albumentations-1.4.14-py3-none-any.whl (177 kB)\n",
      "Downloading albucore-0.0.14-py3-none-any.whl (8.5 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.0-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.2-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp310-cp310-macosx_12_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: tifffile, pydantic-core, opencv-python-headless, lazy-loader, imageio, eval-type-backport, annotated-types, scikit-image, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.14 albumentations-1.4.14 annotated-types-0.7.0 eval-type-backport-0.2.0 imageio-2.35.1 lazy-loader-0.4 opencv-python-headless-4.10.0.84 pydantic-2.9.0 pydantic-core-2.23.2 scikit-image-0.24.0 tifffile-2024.8.30\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "# Define paths\n",
    "input_image_folder = '/Users/hannahgillespie/Google Drive/My Drive/Imperial College London/Thesis/data/images'  # Replace with your image folder path\n",
    "input_label_folder = '/Users/hannahgillespie/Google Drive/My Drive/Imperial College London/Thesis/data/labels'  # Replace with your label folder path\n",
    "output_image_folder = '/Users/hannahgillespie/Google Drive/My Drive/Imperial College London/Thesis/data/images'  # Replace with the output folder path\n",
    "output_label_folder = '/Users/hannahgillespie/Google Drive/My Drive/Imperial College London/Thesis/data/labels'  # Replace with the output folder path\n",
    "text_file = '/Users/hannahgillespie/aod_detection/model/data_specs/synthetic.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n",
      "\u001b[1;32m    106\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_image_folder, file_name)\n",
      "\u001b[1;32m    107\u001b[0m     label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_label_folder, file_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[1;32m    109\u001b[0m         augment_image(image_path, label_path)\n",
      "\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Close all OpenCV windows\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/ros2_env/lib/python3.10/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define augmentation pipeline with individual steps\n",
    "augmentations = {\n",
    "    'GaussianBlur': A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "    'MotionBlur': A.MotionBlur(blur_limit=(3, 7), p=1.0),\n",
    "    'HorizontalFlip': A.HorizontalFlip(p=1.0),\n",
    "    'RandomRotate90': A.RandomRotate90(p=1.0),\n",
    "    'HueSaturationValue': A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0),\n",
    "    'RandomBrightnessContrast': A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "    'GaussNoise': A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "    'Rotate': A.Rotate(limit=10, p=1.0),\n",
    "    'Resize': A.Resize(480, 640, p=1.0)\n",
    "}\n",
    "\n",
    "# Function to clip and round bounding boxes\n",
    "def clip_and_round_bboxes(bboxes, decimals=6):\n",
    "    clipped_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x_center, y_center, width, height = bbox\n",
    "        # Clip to range [0, 1]\n",
    "        x_center = np.clip(x_center, 0, 1)\n",
    "        y_center = np.clip(y_center, 0, 1)\n",
    "        width = np.clip(width, 0, 1)\n",
    "        height = np.clip(height, 0, 1)\n",
    "        # Round to avoid floating-point errors\n",
    "        x_center = round(x_center, decimals)\n",
    "        y_center = round(y_center, decimals)\n",
    "        width = round(width, decimals)\n",
    "        height = round(height, decimals)\n",
    "        clipped_bboxes.append((x_center, y_center, width, height))\n",
    "    return clipped_bboxes\n",
    "\n",
    "# Function to draw bounding boxes on the image\n",
    "def draw_bboxes(image, bboxes, class_labels):\n",
    "    height, width = image.shape[:2]\n",
    "    for bbox, label in zip(bboxes, class_labels):\n",
    "        x_center, y_center, w, h = bbox\n",
    "        # Convert normalized coordinates to absolute values\n",
    "        x1 = int((x_center - w / 2) * width)\n",
    "        y1 = int((y_center - h / 2) * height)\n",
    "        x2 = int((x_center + w / 2) * width)\n",
    "        y2 = int((y_center + h / 2) * height)\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Ensure the text is drawn within the image boundaries\n",
    "        text_x = max(x1, 0)\n",
    "        text_y = max(y1 - 10, 10)  # Adjusted y-position to be above the box and within the image\n",
    "\n",
    "        # Put the class label text with improved visibility\n",
    "        cv2.putText(image, str(label), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Function to apply individual augmentations and save each result\n",
    "def augment_image(image_path, label_path):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Read YOLO label\n",
    "    with open(label_path, 'r') as file:\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        for line in file:\n",
    "            class_id, x_center, y_center, w, h = map(float, line.split())\n",
    "            bboxes.append([x_center, y_center, w, h])\n",
    "            class_labels.append(int(class_id))\n",
    "\n",
    "    # Apply and save each augmentation\n",
    "    for aug_name, aug in augmentations.items():\n",
    "        augmented = aug(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_bboxes = augmented['bboxes']\n",
    "        augmented_class_labels = augmented['class_labels']\n",
    "\n",
    "        # Clip and round bounding boxes to be within the range [0, 1]\n",
    "        augmented_bboxes = clip_and_round_bboxes(augmented_bboxes)\n",
    "\n",
    "        # Draw bounding boxes on the augmented image\n",
    "        #augmented_image_with_bboxes = draw_bboxes(augmented_image.copy(), augmented_bboxes, augmented_class_labels)\n",
    "\n",
    "        # Display the augmented image\n",
    "        #cv2.imshow(augmented_image_with_bboxes)\n",
    "        #cv2.waitKey(1)  # Display each image for 500 milliseconds (adjust as needed)\n",
    "\n",
    "        # Save augmented image with augmentation name\n",
    "        output_image_path = os.path.join(output_image_folder, f'aug_{aug_name}_{os.path.basename(image_path)}')\n",
    "        cv2.imwrite(output_image_path, augmented_image)\n",
    "\n",
    "        # Save augmented labels\n",
    "        output_label_path = os.path.join(output_label_folder, f'aug_{aug_name}_{os.path.basename(label_path)}')\n",
    "        with open(output_label_path, 'w') as file:\n",
    "            for bbox, class_id in zip(augmented_bboxes, augmented_class_labels):\n",
    "                file.write(f\"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")\n",
    "\n",
    "        # Save the augmented image name to the text file\n",
    "        with open(text_file, 'a') as file:\n",
    "            print(f'aug_{aug_name}_{os.path.basename(image_path)}\\n')\n",
    "            file.write(f'aug_{aug_name}_{os.path.basename(image_path)}\\n')\n",
    "\n",
    "# List all image filenames in the folder\n",
    "image_filenames = [f for f in os.listdir(input_image_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Perform augmentation on the selected images\n",
    "for file_name in image_filenames:\n",
    "    image_path = os.path.join(input_image_folder, file_name)\n",
    "    label_path = os.path.join(input_label_folder, file_name.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "    if os.path.exists(label_path):\n",
    "        augment_image(image_path, label_path)\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
